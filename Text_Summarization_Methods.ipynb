{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNsAYloOjzwPPHqz4kKoIiP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raviteja-padala/NLP/blob/main/Text_Summarization_Methods.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploring Text Summarization Methods and Tools: A Comprehensive Overview"
      ],
      "metadata": {
        "id": "dJv635ATRBug"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Objective:\n",
        "The objective of this notebook is to provide a comprehensive understanding of text summarization, including both extractive and abstractive methods, and to explore the tools and metrics commonly used in the field. Through practical examples and discussions, we aim to equip  knowledge and resources necessary to implement and evaluate text summarization techniques effectively in natural language processing tasks."
      ],
      "metadata": {
        "id": "EjU1IsusRQPC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text summarization\n",
        "Text summarization is the process of condensing a lengthy piece of text or document into a shorter, coherent version while retaining its essential information and key ideas. It aims to provide a concise overview, enabling readers to grasp the main points without having to read the entire text. Text summarization can be achieved through extractive methods (selecting and combining existing text) or abstractive methods (generating new text that conveys the same ideas). It finds applications in various fields, including news articles, research papers, social media, and more, where information needs to be presented in a more concise and digestible form."
      ],
      "metadata": {
        "id": "W0ugP1KTRGBB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Extractive Methods:**\n",
        "\n",
        "1. **Sentence Ranking:** Extractive summarization methods often involve ranking sentences based on their importance or relevance to the main theme of the text. Sentences with higher scores are selected for the summary. Techniques like TF-IDF (Term Frequency-Inverse Document Frequency) and TextRank are commonly used for sentence ranking.\n",
        "\n",
        "2. **Graph-Based Approaches:** TextRank and PageRank algorithms, which are inspired by web page ranking algorithms, can be applied to create graphs of sentences or words in the text. Sentences with more connections or links to other sentences are considered more important and are included in the summary.\n",
        "\n",
        "3. **Machine Learning:** Machine learning models, such as Support Vector Machines (SVMs) or neural networks, can be trained to predict the importance of sentences based on various features, such as sentence length, word frequency, and more. These models can then be used to select sentences for the summary.\n",
        "\n",
        "**Abstractive Methods:**\n",
        "\n",
        "1. **Seq2Seq Models:** Abstractive summarization involves generating a summary in a more human-like way, often by paraphrasing or rephrasing the content. Sequence-to-Sequence (Seq2Seq) models, which are commonly used in machine translation, can be adapted for abstractive summarization. These models take the input text and generate a summary in a more creative manner.\n",
        "\n",
        "2. **Transformer Models:** Transformer-based models, such as GPT (Generative Pre-trained Transformer) and BERT (Bidirectional Encoder Representations from Transformers), have been used for abstractive summarization. They can understand context and generate coherent summaries by predicting the next words in the summary sequence.\n",
        "\n",
        "3. **Reinforcement Learning:** Some abstractive summarization methods use reinforcement learning techniques to fine-tune the generated summaries. Reinforcement learning rewards models for producing summaries that are not only informative but also fluent and concise.\n",
        "\n",
        "4. **Pointer-Generator Networks:** These networks combine extractive and abstractive techniques by allowing the model to choose between copying words directly from the source text (extractive) and generating new words (abstractive) based on the context. This approach helps in retaining important phrases while generating novel content.\n",
        "\n",
        "5. **Abstractive Evaluation Metrics:** Metrics like ROUGE (Recall-Oriented Understudy for Gisting Evaluation) and METEOR (Metric for Evaluation of Translation with Explicit ORdering) are used to evaluate abstractive summaries by comparing them to reference summaries.\n",
        "\n",
        "Both extractive and abstractive methods have their advantages and limitations, and the choice of method depends on the specific requirements and goals of the summarization task."
      ],
      "metadata": {
        "id": "9AaOYu0MLtIW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are several tools and libraries available for both extractive and abstractive text summarization tasks. Here are some popular ones:\n",
        "\n",
        "**Tools for Extractive Summarization:**\n",
        "\n",
        "1. **Gensim:** Gensim is a Python library that includes the `summarize` function for extractive summarization using techniques like TF-IDF and TextRank.\n",
        "\n",
        "2. **NLTK (Natural Language Toolkit):** NLTK is a comprehensive library for natural language processing in Python, and it provides various tools for text summarization, including sentence ranking and keyword extraction.\n",
        "\n",
        "3. **BERTSUM:** BERTSUM is a library that leverages pre-trained BERT models for extractive summarization. It is particularly useful for summarizing longer documents.\n",
        "\n",
        "4. **BERT Extractive Summarizer (Bert-extractive-summarizer):** This Python library is specifically designed for extractive summarization using BERT-based models.\n",
        "\n",
        "5. **Sumy:** Sumy is a simple library that provides various algorithms for extractive summarization, such as LSA, LexRank, and TextRank.\n",
        "\n",
        "**Tools for Abstractive Summarization:**\n",
        "\n",
        "1. **Hugging Face Transformers:** Hugging Face's Transformers library provides pre-trained models for abstractive summarization, including GPT-2 and T5. You can fine-tune these models for specific summarization tasks.\n",
        "\n",
        "2. **OpenNMT:** OpenNMT is an open-source neural machine translation framework that can be adapted for abstractive summarization tasks. It allows you to train your own models.\n",
        "\n",
        "3. **BART (Facebook's AI Research):** BART is a pre-trained sequence-to-sequence model designed for various natural language generation tasks, including abstractive summarization.\n",
        "\n",
        "4. **T2T (Tensor2Tensor):** T2T is an open-source library from Google that provides various models and tools for sequence-to-sequence tasks, making it suitable for abstractive summarization.\n",
        "\n",
        "5. **GPT-3 (OpenAI):** While GPT-3 is primarily known for its generative capabilities, it can be used for abstractive summarization tasks by conditioning the model on the input text and generating summaries.\n",
        "\n",
        "6. **SummarizeBot:** SummarizeBot is an online service that uses AI to generate abstractive summaries of text, documents, and web pages.\n",
        "\n",
        "These tools and libraries vary in terms of complexity, capabilities, and ease of use. The choice of tool or library depends on your specific requirements and the complexity of your summarization task. Some tools are more suitable for research and experimentation, while others are designed for production-ready applications."
      ],
      "metadata": {
        "id": "CqHTvCZvLzvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Length-Based Extractive Summarization:**\n",
        "\n",
        "Length-based extractive summarization is a straightforward approach to summarization where the length of sentences or paragraphs is the primary criterion for selecting content to include in the summary. In this method, longer sentences or paragraphs are often considered more informative or comprehensive, so they are prioritized for inclusion in the summary.\n",
        "\n",
        "Here's how length-based extractive summarization works:\n",
        "\n",
        "1. **Sentence Ranking by Length:** The input text is divided into sentences or paragraphs, depending on the granularity desired for the summary.\n",
        "\n",
        "2. **Sorting by Length:** The sentences or paragraphs are then sorted in descending order based on their length, with the longest ones coming first.\n",
        "\n",
        "3. **Selecting Top Sentences:** A predetermined number of sentences (or a desired length of text) is selected from the sorted list, typically starting with the longest sentences and working downward. These selected sentences are assembled to form the summary.\n",
        "\n",
        "Pros of Length-Based Extractive Summarization:\n",
        "- Simplicity: It's a simple and intuitive method that doesn't require complex algorithms.\n",
        "- Preserves Context: Longer sentences may capture more context and details from the original text.\n",
        "\n",
        "Cons of Length-Based Extractive Summarization:\n",
        "- May Miss Key Information: Longer sentences are not necessarily more informative. Important information might be present in shorter sentences.\n",
        "- Lack of Content Selection: This method doesn't consider the content's semantic meaning or importance; it solely relies on sentence length.\n"
      ],
      "metadata": {
        "id": "9_jZRBNUIOdH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Length-Based Extractive Summarization"
      ],
      "metadata": {
        "id": "oyG1WvpMMzd5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Install and Load spaCy\n",
        "Install the spaCy library and load an appropriate language model."
      ],
      "metadata": {
        "id": "k05Nztae9Jst"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "VUojtymt9Ome"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Define the Input Text\n",
        "Define the text that you want to summarize."
      ],
      "metadata": {
        "id": "qFgBNnqu9Q2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample text for summarization\n",
        "text = \"\"\"\n",
        "Text summarization is the process of condensing a lengthy document or piece of text into a shorter, coherent version while preserving its key ideas, concepts, and most important information. The objective of text summarization is to provide readers with a concise overview of the original text, enabling them to quickly grasp the main points without having to read the entire document.\n",
        "\n",
        "There are two main approaches to text summarization:\n",
        "\n",
        "1. Extractive Summarization: In extractive summarization, the summary is created by selecting and extracting sentences or phrases directly from the original text. These selected sentences are typically the ones that contain the most important information or convey the main ideas of the document. Extractive summarization methods often use techniques like ranking sentences based on their relevance and importance, such as using algorithms like TextRank or TF-IDF (Term Frequency-Inverse Document Frequency).\n",
        "\n",
        "2. Abstractive Summarization: Abstractive summarization involves generating a summary that may not necessarily reuse the exact words or phrases from the original text. Instead, it aims to generate a summary in a more human-like way by paraphrasing and rephrasing the content. Abstractive summarization methods often use natural language processing (NLP) techniques, such as neural networks and sequence-to-sequence models, to understand the content and generate coherent and concise summaries.\n",
        "\n",
        "Text summarization has various applications, including:\n",
        "\n",
        "- News summarization: Creating concise news articles or headlines from longer news reports.\n",
        "- Document summarization: Summarizing research papers, legal documents, or business reports.\n",
        "- Social media summarization: Generating short descriptions or summaries of social media posts.\n",
        "- Search engine result snippets: Displaying concise summaries of web pages in search engine results.\n",
        "- Content recommendation: Providing brief descriptions of articles or videos to help users decide what to read or watch.\n",
        "\n",
        "Text summarization is a challenging task in natural language processing, and it plays a significant role in information retrieval and content consumption, particularly in situations where people need to quickly grasp the main points of lengthy texts.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "GTcZVptf9UHV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Tokenize and Process the Text\n",
        "Use spaCy to tokenize and process the input text:"
      ],
      "metadata": {
        "id": "TgN5FntH9Z5l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(text)"
      ],
      "metadata": {
        "id": "t9v9y_IH9dGO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = [token.text for token in doc]\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrRVK7Sq_sfN",
        "outputId": "88d3913b-7121-4878-b77d-89cc6b02ac70"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\n', 'Text', 'summarization', 'is', 'the', 'process', 'of', 'condensing', 'a', 'lengthy', 'document', 'or', 'piece', 'of', 'text', 'into', 'a', 'shorter', ',', 'coherent', 'version', 'while', 'preserving', 'its', 'key', 'ideas', ',', 'concepts', ',', 'and', 'most', 'important', 'information', '.', 'The', 'objective', 'of', 'text', 'summarization', 'is', 'to', 'provide', 'readers', 'with', 'a', 'concise', 'overview', 'of', 'the', 'original', 'text', ',', 'enabling', 'them', 'to', 'quickly', 'grasp', 'the', 'main', 'points', 'without', 'having', 'to', 'read', 'the', 'entire', 'document', '.', '\\n\\n', 'There', 'are', 'two', 'main', 'approaches', 'to', 'text', 'summarization', ':', '\\n\\n', '1', '.', 'Extractive', 'Summarization', ':', 'In', 'extractive', 'summarization', ',', 'the', 'summary', 'is', 'created', 'by', 'selecting', 'and', 'extracting', 'sentences', 'or', 'phrases', 'directly', 'from', 'the', 'original', 'text', '.', 'These', 'selected', 'sentences', 'are', 'typically', 'the', 'ones', 'that', 'contain', 'the', 'most', 'important', 'information', 'or', 'convey', 'the', 'main', 'ideas', 'of', 'the', 'document', '.', 'Extractive', 'summarization', 'methods', 'often', 'use', 'techniques', 'like', 'ranking', 'sentences', 'based', 'on', 'their', 'relevance', 'and', 'importance', ',', 'such', 'as', 'using', 'algorithms', 'like', 'TextRank', 'or', 'TF', '-', 'IDF', '(', 'Term', 'Frequency', '-', 'Inverse', 'Document', 'Frequency', ')', '.', '\\n\\n', '2', '.', 'Abstractive', 'Summarization', ':', 'Abstractive', 'summarization', 'involves', 'generating', 'a', 'summary', 'that', 'may', 'not', 'necessarily', 'reuse', 'the', 'exact', 'words', 'or', 'phrases', 'from', 'the', 'original', 'text', '.', 'Instead', ',', 'it', 'aims', 'to', 'generate', 'a', 'summary', 'in', 'a', 'more', 'human', '-', 'like', 'way', 'by', 'paraphrasing', 'and', 'rephrasing', 'the', 'content', '.', 'Abstractive', 'summarization', 'methods', 'often', 'use', 'natural', 'language', 'processing', '(', 'NLP', ')', 'techniques', ',', 'such', 'as', 'neural', 'networks', 'and', 'sequence', '-', 'to', '-', 'sequence', 'models', ',', 'to', 'understand', 'the', 'content', 'and', 'generate', 'coherent', 'and', 'concise', 'summaries', '.', '\\n\\n', 'Text', 'summarization', 'has', 'various', 'applications', ',', 'including', ':', '\\n\\n', '-', 'News', 'summarization', ':', 'Creating', 'concise', 'news', 'articles', 'or', 'headlines', 'from', 'longer', 'news', 'reports', '.', '\\n', '-', 'Document', 'summarization', ':', 'Summarizing', 'research', 'papers', ',', 'legal', 'documents', ',', 'or', 'business', 'reports', '.', '\\n', '-', 'Social', 'media', 'summarization', ':', 'Generating', 'short', 'descriptions', 'or', 'summaries', 'of', 'social', 'media', 'posts', '.', '\\n', '-', 'Search', 'engine', 'result', 'snippets', ':', 'Displaying', 'concise', 'summaries', 'of', 'web', 'pages', 'in', 'search', 'engine', 'results', '.', '\\n', '-', 'Content', 'recommendation', ':', 'Providing', 'brief', 'descriptions', 'of', 'articles', 'or', 'videos', 'to', 'help', 'users', 'decide', 'what', 'to', 'read', 'or', 'watch', '.', '\\n\\n', 'Text', 'summarization', 'is', 'a', 'challenging', 'task', 'in', 'natural', 'language', 'processing', ',', 'and', 'it', 'plays', 'a', 'significant', 'role', 'in', 'information', 'retrieval', 'and', 'content', 'consumption', ',', 'particularly', 'in', 'situations', 'where', 'people', 'need', 'to', 'quickly', 'grasp', 'the', 'main', 'points', 'of', 'lengthy', 'texts', '.', '\\n']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Generate a Summary\n",
        "Generate a summary by selecting the top N sentences based on your chosen criteria. In this example, we sorted sentences by length:"
      ],
      "metadata": {
        "id": "CykO3fmI9ipW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a list of sentences ranked by importance (using sentence length as a simple metric)\n",
        "sentences = [sentence.text for sentence in doc.sents]\n",
        "sentences.sort(key=lambda x: len(x), reverse=True)\n",
        "\n",
        "# Generate the summary by selecting the top N sentences (e.g., top 3 sentences)\n",
        "summary = \" \".join(sentences[:3])  # Adjust the number to control summary length"
      ],
      "metadata": {
        "id": "rL4qBYLe9j9d"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Count Words in the Original Text and Summary\n",
        "Count the number of words in both the original text and the summary:"
      ],
      "metadata": {
        "id": "zXInalqv96dd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the number of words in the original text and the summary\n",
        "num_words_in_text = len([token for token in doc if not token.is_punct and not token.is_space])\n",
        "num_words_in_summary = len([token for token in nlp(summary) if not token.is_punct and not token.is_space])"
      ],
      "metadata": {
        "id": "lGmfuZmf9791"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 6: Print the Results\n",
        "Print the number of words in the original text, the number of words in the summary, and the summary itself:"
      ],
      "metadata": {
        "id": "1-pE7WtS-EAu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the number of words in the original text\n",
        "print(f\"Number of words in the original text: {num_words_in_text}\")\n",
        "\n",
        "# Print the number of words in the summary\n",
        "print(f\"Number of words in the summary: {num_words_in_summary}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyqiPA3t-FN9",
        "outputId": "6a7b90ef-8823-416c-f0f7-68ba4903c0be"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words in the original text: 321\n",
            "Number of words in the summary: 95\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the summarized text\n",
        "print(summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mL24GU3V-_bH",
        "outputId": "64a723ef-ee48-48f1-ac58-39d82e8f7429"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text summarization is a challenging task in natural language processing, and it plays a significant role in information retrieval and content consumption, particularly in situations where people need to quickly grasp the main points of lengthy texts.\n",
            " Abstractive summarization methods often use natural language processing (NLP) techniques, such as neural networks and sequence-to-sequence models, to understand the content and generate coherent and concise summaries.\n",
            "\n",
            " Extractive summarization methods often use techniques like ranking sentences based on their relevance and importance, such as using algorithms like TextRank or TF-IDF (Term Frequency-Inverse Document Frequency).\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 6: BLEU score for a text summarization\n",
        "\n",
        "The BLEU (Bilingual Evaluation Understudy) score is a metric used for evaluating the quality of machine-generated text, especially in the context of machine translation. It was originally developed to evaluate the quality of machine-generated translations by comparing them to human reference translations. BLEU is widely used in natural language processing (NLP) and machine translation tasks.\n",
        "\n",
        "**Purpose:** BLEU is used to measure how closely a machine-generated text (such as a translation) matches one or more reference texts (human-generated translations or summaries). It assesses the quality of the generated text by comparing it to the reference(s).\n",
        "\n",
        "**BLEU Score Calculation:** The overall BLEU score is computed by taking the geometric mean of the precision scores for different N-gram lengths, weighted equally. The brevity penalty is also factored into the final score.\n",
        "\n",
        "**N-grams:** BLEU primarily uses the concept of N-grams, which are sequences of N words. It calculates precision scores for N-grams of varying lengths (typically 1 to 4) in both the generated and reference texts.\n",
        "\n",
        "**Precision**: For each N-gram length, BLEU calculates the precision, which is the ratio of the number of N-grams in the generated text that appear in the reference text to the total number of N-grams in the generated text. Higher precision scores indicate better overlap with the reference.\n",
        "\n",
        "**Range of Scores:** BLEU scores typically range from 0 to 1, with 1 indicating a perfect match between the generated and reference texts.\n",
        "\n",
        "**Limitations:** While BLEU is a widely used metric, it has limitations. It relies solely on N-gram matching and does not capture higher-level language understanding or fluency."
      ],
      "metadata": {
        "id": "9ul5rp87Bl3O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.translate.bleu_score import sentence_bleu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZVq86yTDDWw",
        "outputId": "fb07e794-8735-4d2f-8d0d-95c05015034e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reference summaries (human-generated)\n",
        "reference_summaries = [\n",
        "    \"Text summarization condenses lengthy text into a shorter, coherent version.\",\n",
        "    \"Text summarization is used in various applications, including news and document summarization.\"\n",
        "]\n",
        "\n",
        "\n",
        "# Tokenize the reference summaries and machine-generated summary\n",
        "reference_summaries = [nltk.word_tokenize(summary.lower()) for summary in reference_summaries]\n",
        "machine_summary = nltk.word_tokenize(summary.lower())\n",
        "\n",
        "# Calculate the BLEU score\n",
        "bleu_score = sentence_bleu(reference_summaries, machine_summary)\n",
        "\n",
        "\n",
        "# Print the BLEU score\n",
        "print(f\"BLEU Score: {bleu_score}\")\n",
        "\n",
        "# We added reference summaries as a list of human-generated summaries.\n",
        "\n",
        " #We tokenized the reference summaries and the machine-generated summary using"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTvN1kgECd4d",
        "outputId": "5acad43a-8dca-4376-cc9b-0c309c539133"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU Score: 8.42265914601564e-79\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We have added a new set of reference summaries for a more meaningful BLEU score calculation.\n",
        "# We use smoothing with SmoothingFunction().method4 to handle cases where N-grams have zero counts.\n",
        "# Smoothing is important to prevent division by zero and provide a more accurate BLEU score.\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "\n",
        "# Reference summaries (human-generated)\n",
        "reference_summaries = [\n",
        "    \"Text summarization is the process of condensing lengthy text into a shorter, coherent version while preserving key ideas.\",\n",
        "    \"Extractive and abstractive summarization are two approaches to summarizing text.\",\n",
        "]\n",
        "\n",
        "# Calculate the BLEU score with smoothing\n",
        "smoothie = SmoothingFunction().method4  # Use method 4 for smoothing\n",
        "bleu_score = sentence_bleu(reference_summaries, machine_summary, smoothing_function=smoothie)\n",
        "\n",
        "# Print the BLEU score\n",
        "print(f\"BLEU Score: {bleu_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSDFHQDDDwN1",
        "outputId": "74486bf1-5d79-44df-80d5-40d52289574d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU Score: 0.003907733550782797\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "hTt9yYyYGMgN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **Frequency-Based Extractive Summarization:**\n",
        "\n",
        "Frequency-based extractive summarization, on the other hand, uses word frequency statistics to identify and select important sentences for the summary. The underlying idea is that sentences containing frequently occurring words or phrases are more likely to be relevant and informative.\n",
        "\n",
        "Here's how frequency-based extractive summarization works:\n",
        "\n",
        "1. **Calculating Word Frequencies:** The input text is tokenized into words, and the frequency of each word is calculated. Common stopwords (e.g., \"the,\" \"and\") are often excluded from this analysis.\n",
        "\n",
        "2. **Assigning Sentence Scores:** Sentences are scored based on the sum of word frequencies present in each sentence. Sentences containing words with higher frequencies receive higher scores.\n",
        "\n",
        "3. **Selecting Top Sentences:** A predetermined number of top-scoring sentences are selected to compose the summary.\n",
        "\n",
        "Pros of Frequency-Based Extractive Summarization:\n",
        "- Content Relevance: It considers the importance of words in the text, making it more likely to select sentences with relevant information.\n",
        "- Flexibility: It can be adapted to different languages and domains.\n",
        "\n",
        "Cons of Frequency-Based Extractive Summarization:\n",
        "- Limited Semantics: It focuses on word frequency and may not capture the nuanced semantics or context of the text.\n",
        "- Ignores Rare Terms: It may overlook less frequent but crucial terms or concepts.\n",
        "\n",
        "In summary, length-based extractive summarization prioritizes longer sentences or paragraphs, while frequency-based extractive summarization emphasizes the importance of frequently occurring words when selecting sentences for the summary. Both methods have their strengths and weaknesses, and the choice between them depends on the specific summarization task and objectives."
      ],
      "metadata": {
        "id": "MDUqm74DM1cO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Frequency-Based Extractive Summarization:"
      ],
      "metadata": {
        "id": "LUimlIbSM5lq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Load SpaCy and Language Model"
      ],
      "metadata": {
        "id": "s36I13FDIzMv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "from string import punctuation\n",
        "\n",
        "# Load the English language model from spaCy\n",
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "lSPoPJ_4I23I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Define Sample Text and Preprocessing\n",
        "\n",
        "we define the sample text for summarization and prepare for text preprocessing. We create a SpaCy document object from the sample text, define a set of common stopwords, and add extra punctuation characters for consideration."
      ],
      "metadata": {
        "id": "KWgVzb-9I4pY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample text for summarization\n",
        "text = \"\"\"\n",
        "Text summarization is the process of condensing a lengthy document or piece of text into a shorter, coherent version while preserving its key ideas, concepts, and most important information. The objective of text summarization is to provide readers with a concise overview of the original text, enabling them to quickly grasp the main points without having to read the entire document.\n",
        "\n",
        "There are two main approaches to text summarization:\n",
        "\n",
        "1. Extractive Summarization: In extractive summarization, the summary is created by selecting and extracting sentences or phrases directly from the original text. These selected sentences are typically the ones that contain the most important information or convey the main ideas of the document. Extractive summarization methods often use techniques like ranking sentences based on their relevance and importance, such as using algorithms like TextRank or TF-IDF (Term Frequency-Inverse Document Frequency).\n",
        "\n",
        "2. Abstractive Summarization: Abstractive summarization involves generating a summary that may not necessarily reuse the exact words or phrases from the original text. Instead, it aims to generate a summary in a more human-like way by paraphrasing and rephrasing the content. Abstractive summarization methods often use natural language processing (NLP) techniques, such as neural networks and sequence-to-sequence models, to understand the content and generate coherent and concise summaries.\n",
        "\n",
        "Text summarization has various applications, including:\n",
        "\n",
        "- News summarization: Creating concise news articles or headlines from longer news reports.\n",
        "- Document summarization: Summarizing research papers, legal documents, or business reports.\n",
        "- Social media summarization: Generating short descriptions or summaries of social media posts.\n",
        "- Search engine result snippets: Displaying concise summaries of web pages in search engine results.\n",
        "- Content recommendation: Providing brief descriptions of articles or videos to help users decide what to read or watch.\n",
        "\n",
        "Text summarization is a challenging task in natural language processing, and it plays a significant role in information retrieval and content consumption, particularly in situations where people need to quickly grasp the main points of lengthy texts.\n",
        "\"\"\"\n",
        "\n",
        "# Define a sample text for summarization\n",
        "doc = nlp(text)\n",
        "\n",
        "# Define a set of stopwords (common words to be ignored in text analysis)\n",
        "stopwords = list(STOP_WORDS)\n",
        "\n",
        "# Define additional punctuation characters to be considered\n",
        "punctuation = punctuation + '\\n'\n"
      ],
      "metadata": {
        "id": "7gO5hnV6JC1X"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Calculate Word Frequencies\n",
        "calculate the word frequencies in the document. We iterate through each word in the SpaCy document and update the word frequencies in a dictionary, excluding stopwords and punctuation."
      ],
      "metadata": {
        "id": "qL-cEqrYJLyW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dictionary to store word frequencies\n",
        "word_frequencies = {}\n",
        "\n",
        "# Iterate through each word in the document\n",
        "for word in doc:\n",
        "    # Check if the word is not a stop word and not in the punctuation set\n",
        "    if word.text.lower() not in stopwords and word.text.lower() not in punctuation:\n",
        "        # Update word frequencies in the dictionary\n",
        "        if word.text not in word_frequencies.keys():\n",
        "            word_frequencies[word.text] = 1\n",
        "        else:\n",
        "            word_frequencies[word.text] += 1"
      ],
      "metadata": {
        "id": "cRkVDPwUJQpo"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Normalize Word Frequencies\n",
        "\n",
        " find the maximum word frequency and then normalize all word frequencies by dividing each frequency by the maximum frequency. This normalization step scales all frequencies to a range between 0 and 1."
      ],
      "metadata": {
        "id": "khViXUhZJVRG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the maximum word frequency\n",
        "max_frequency = max(word_frequencies.values())\n",
        "\n",
        "# Normalize word frequencies by dividing by the maximum frequency\n",
        "for word in word_frequencies.keys():\n",
        "    word_frequencies[word] = word_frequencies[word] / max_frequency\n"
      ],
      "metadata": {
        "id": "SXOng7dvJWf4"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5: Tokenize Sentences\n",
        "\n",
        "tokenize the document into sentences using SpaCy's sentence tokenizer, and the result is stored in the sentence_tokens list."
      ],
      "metadata": {
        "id": "-_yOS8rQJeyg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the document into sentences\n",
        "sentence_tokens = [sent for sent in doc.sents]"
      ],
      "metadata": {
        "id": "xUfd4niEJj3P"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 6: Calculate Sentence Scores\n",
        "\n",
        "calculate sentence scores. For each sentence, we iterate through its words and calculate a score based on the sum of the normalized word frequencies present in that sentence."
      ],
      "metadata": {
        "id": "-mI1lm9KJmJW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dictionary to store sentence scores\n",
        "sentence_scores = {}\n",
        "\n",
        "# Calculate sentence scores based on the sum of normalized word frequencies\n",
        "for sent in sentence_tokens:\n",
        "    for word in sent:\n",
        "        if word.text.lower() in word_frequencies.keys():\n",
        "            if sent not in sentence_scores.keys():\n",
        "                sentence_scores[sent] = word_frequencies[word.text.lower()]\n",
        "            else:\n",
        "                sentence_scores[sent] += word_frequencies[word.text.lower()]"
      ],
      "metadata": {
        "id": "QdzONsUCJsLv"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 7: Select Top Sentences for Summary\n",
        "we import the nlargest function from the heapq module. We determine the number of sentences to include in the summary (30% of the total sentences) and then use nlargest to select the top sentences with the highest scores based on the sentence scores dictionary."
      ],
      "metadata": {
        "id": "iNgRGfQEJx9m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import nlargest from heapq to select the top sentences for the summary\n",
        "from heapq import nlargest\n",
        "\n",
        "# Determine the number of sentences to include in the summary (30% of total sentences)\n",
        "select_length = int(len(sentence_tokens) * 0.3)\n",
        "\n",
        "# Select the top sentences with the highest scores to form the summary\n",
        "summary = nlargest(select_length, sentence_scores, key=sentence_scores.get)\n"
      ],
      "metadata": {
        "id": "PfAbyVJcJ1_g"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 8: Generate Final Summary\n",
        "\n",
        "we create the final summary by joining the selected sentences into a list of words and then joining those words into a single string. The result is the generated summary."
      ],
      "metadata": {
        "id": "swDbaF6ZJ6i4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a final summary by joining the selected sentences\n",
        "final_summary = [word.text for word in summary]\n",
        "\n",
        "# Join the final summary sentences into a single string\n",
        "summary = ' '.join(final_summary)\n",
        "\n",
        "# Print the final summary\n",
        "print(summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "It6y9sXZKBjo",
        "outputId": "247daf8a-1c32-4f5f-e613-3e7b4f8618cc"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text summarization is a challenging task in natural language processing, and it plays a significant role in information retrieval and content consumption, particularly in situations where people need to quickly grasp the main points of lengthy texts.\n",
            " The objective of text summarization is to provide readers with a concise overview of the original text, enabling them to quickly grasp the main points without having to read the entire document.\n",
            "\n",
            " Text summarization has various applications, including:\n",
            "\n",
            "- News summarization: Creating concise news articles or headlines from longer news reports.\n",
            " Abstractive summarization methods often use natural language processing (NLP) techniques, such as neural networks and sequence-to-sequence models, to understand the content and generate coherent and concise summaries.\n",
            "\n",
            " \n",
            "Text summarization is the process of condensing a lengthy document or piece of text into a shorter, coherent version while preserving its key ideas, concepts, and most important information.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step9 : BLEU score"
      ],
      "metadata": {
        "id": "6nDx3iYkKg1R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reference summaries (human-generated)\n",
        "reference_summaries = [\n",
        "    \"Text summarization condenses lengthy text into a shorter, coherent version.\",\n",
        "    \"Text summarization is used in various applications, including news and document summarization.\"\n",
        "]\n",
        "\n",
        "\n",
        "# Tokenize the reference summaries and machine-generated summary\n",
        "reference_summaries = [nltk.word_tokenize(summary.lower()) for summary in reference_summaries]\n",
        "machine_summary = nltk.word_tokenize(summary.lower())\n",
        "\n",
        "# Calculate the BLEU score\n",
        "bleu_score = sentence_bleu(reference_summaries, machine_summary)\n",
        "\n",
        "\n",
        "# Print the BLEU score\n",
        "print(f\"BLEU Score: {bleu_score}\")\n",
        "\n",
        "# We added reference summaries as a list of human-generated summaries.\n",
        "\n",
        " #We tokenized the reference summaries and the machine-generated summary using"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsJaMDiTKS6m",
        "outputId": "fc3bafbb-1aea-4885-ad50-08acb039afb6"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU Score: 0.0603470671902595\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Length-Based Extractive Summarization\n",
        "\n",
        "\n",
        "- Length-Based Extractive Summarization selects and extracts sentences directly from the original text to create the summary.\n",
        "- It uses spaCy for natural language processing and sentence tokenization.\n",
        "- The length of the summary is controlled by selecting the top N sentences, which are ranked by their length (longest sentences are selected).\n",
        "- Length-Based Extractive Summarization does not consider word frequencies or scores for sentence selection; it simply selects the longest sentences.\n",
        "\n",
        "###  Frequency-Based Extractive Summarization\n",
        "\n",
        "- Frequency-Based Extractive Summarization aims to perform extractive summarization with a different approach.\n",
        "- It calculates word frequencies for each word in the document and normalizes these frequencies.\n",
        "- It then assigns scores to sentences based on the sum of normalized word frequencies present in each sentence.\n",
        "- Sentences with higher scores (containing more significant words) are selected for the summary.\n",
        "- The length of the summary is controlled by selecting the top sentences based on their scores, and it's set to be approximately 30% of the total sentences.\n",
        "- Frequency-Based Extractive Summarization provides detailed information on word frequencies and sentence scores.\n",
        "\n",
        "In summary, Length-Based Extractive Summarization is a simpler approach that selects sentences based on length, while Frequency-Based Extractive Summarization employs a more sophisticated approach by considering word frequencies and sentence scores to create the summary. Frequency-Based Extractive Summarization is likely to produce a summary that captures more significant content from the original text, while Length-Based Extractive Summarization may result in a summary that is simply a collection of the longest sentences."
      ],
      "metadata": {
        "id": "IRkujDwfOXn4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion:\n",
        "\n",
        "In this notebook, we delved into the world of text summarization, exploring both extractive and abstractive methods and the tools commonly used in this field.\n",
        "\n",
        "We discussed Length-Based Extractive Summarization, which relies on the length of sentences or paragraphs to determine their inclusion in the summary. We also explored Frequency-Based Extractive Summarization, a method that prioritizes sentences containing frequently occurring words or phrases, and we even delved into calculating BLEU scores to evaluate the quality of machine-generated summaries.\n",
        "\n",
        "In conclusion, text summarization stands as a valuable task within natural language processing, facilitating the extraction of essential information from lengthy texts. The BLEU score, though valuable for evaluation, should be complemented with other metrics, all while considering the specific context and objectives of your summarization task.\n",
        "\n",
        "The choice of summarization method depends on available resources and the unique requirements of the situation, making text summarization an adaptable and essential tool in the realm of information processing."
      ],
      "metadata": {
        "id": "eRVzwb-QOYRX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Thank you for reading till the end."
      ],
      "metadata": {
        "id": "5kjYbfG5R352"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## -Raviteja\n",
        "\n",
        "https://www.linkedin.com/in/raviteja-padala/"
      ],
      "metadata": {
        "id": "H799q42rR9G-"
      }
    }
  ]
}